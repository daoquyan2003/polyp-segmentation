model:
  _target_: src.modules.models.sam_unetr.sam_unetr.SAMUNETR
  img_size: 256
  in_channels: 3
  out_channels: 1
  feature_size: 20
  embed_dim: 1280
  encoder_depth: 32
  encoder_num_heads: 16
  encoder_global_attn_indexes: [7, 15, 23, 31]
  pretrained_image_encoder_path: ${paths.checkpoint_dir}/sam_vit_h_image_encoder.pth
  vit_type: "vit_h"
  trainable_encoder: false
  pretrained: true

loss:
  _target_: "torch.nn.BCEWithLogitsLoss"
  # include_background: true
  # to_onehot_y: false
  # sigmoid: true

metrics:
  main:
    _target_: "torchmetrics.JaccardIndex"
    task: "binary"
    num_classes: 2
    average: "macro"
  valid_best:
    _target_: "torchmetrics.MaxMetric"
