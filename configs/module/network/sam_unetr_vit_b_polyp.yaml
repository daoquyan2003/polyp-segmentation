model:
  _target_: src.modules.models.sam_unetr.sam_unetr.SAMUNETR
  img_size: 256
  in_channels: 3
  out_channels: 1
  feature_size: 12
  embed_dim: 768
  encoder_depth: 12
  encoder_num_heads: 12
  encoder_global_attn_indexes: [2, 5, 8, 11]
  pretrained_image_encoder_path: ${paths.checkpoint_dir}/sam_vit_b_image_encoder.pth
  vit_type: "vit_b"
  trainable_encoder: true
  pretrained: true

loss:
  _target_: "torch.nn.BCEWithLogitsLoss"
  # include_background: true
  # to_onehot_y: false
  # sigmoid: true

metrics:
  main:
    _target_: "torchmetrics.JaccardIndex"
    task: "binary"
    num_classes: 2
    average: "macro"
  valid_best:
    _target_: "torchmetrics.MaxMetric"
